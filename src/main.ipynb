{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import re\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import regexp_tokenize\n",
    "from operator import itemgetter\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import numpy as np\n",
    "\n",
    "def cos_sim(A, B):\n",
    "       return round(dot(A, B)/(norm(A)*norm(B)),3)\n",
    "\n",
    "\n",
    "\n",
    "with open('top_songs.pickle', 'rb') as handle:\n",
    "    dic = pickle.load(handle)\n",
    "\n",
    "# data = pd.read_csv('mylyrics00.csv')\n",
    "\n",
    "singer_list=list(dic.keys())\n",
    "song_list=list(dic.values())\n",
    "\n",
    "\n",
    "\n",
    "stop_word = set(stopwords.words('english'))\n",
    "doc = []\n",
    "for i in range(len(song_list)):\n",
    "    tmp=\"\"\n",
    "    for key in song_list[i].keys():\n",
    "        temp=song_list[i][key]\n",
    "        tmp=tmp+\" \"+temp\n",
    "\n",
    "    \n",
    "    \n",
    "    list_temp = regexp_tokenize(tmp.lower(), \"[a-z]['a-z]*\")\n",
    "\n",
    "    result = []\n",
    "    for w in list_temp:\n",
    "        if w not in stop_word:\n",
    "            result.append(w)\n",
    "    doc.append([singer_list[i],result])\n",
    "singer=singer_list\n",
    "        \n",
    "# singer = (list(set(list(data.iloc[:-1]['artist']))))\n",
    "# print(singer)\n",
    "\n",
    "\n",
    "\n",
    "# for i in range(len(singer)):\n",
    "#     sing = singer[i]\n",
    "#     temp = \"\"\n",
    "#     #print(len(data.iloc[:-1]['lyrics']))\n",
    "#     for j in range(len(data.iloc[:-1]['lyrics'])):\n",
    "#         if sing == data.iloc[j]['artist']:\n",
    "#             #a = data.iloc[j]['lyrics'].split(' ')\n",
    "#             temp = temp + \" \" + data.iloc[j]['lyrics']\n",
    "#     list_temp = regexp_tokenize(temp.lower(), \"[a-z]['a-z]*\")\n",
    "    \n",
    "#     result = []\n",
    "#     for w in list_temp:\n",
    "#         if w not in stop_word:\n",
    "#             result.append(w)\n",
    "    \n",
    "    \n",
    "#     doc.append([singer[i],result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class List:\n",
    "    class Node:\n",
    "        def __init__(self, doc,dtf): #node는 doc_number,dtf link로 구성\n",
    "            self.doc = doc\n",
    "            self.dtf=dtf\n",
    "            self.next = None\n",
    "\n",
    "    def __init__(self,term): #head는 term,freq,link로 구성\n",
    "        self.head = None\n",
    "        self.term=term\n",
    "        self.freq = 0\n",
    "\n",
    "    def freq(self):\n",
    "        return self.freq\n",
    "\n",
    "    def term(self):\n",
    "        return self.term\n",
    "\n",
    "    def add(self,doc,dtf):\n",
    "        p=self.head\n",
    "        if p==None:\n",
    "            self.head=self.Node(doc,dtf)\n",
    "        else:\n",
    "            while (p.next != None):\n",
    "                p=p.next\n",
    "            p.next = self.Node(doc,dtf)\n",
    "        self.freq += 1\n",
    "\n",
    "    def print_list(self): # doc_number를 출력하기 위한 함수\n",
    "        p=self.head\n",
    "        res=[]\n",
    "        while p is not None:\n",
    "            res.append(p.doc)\n",
    "            p=p.next\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listing(index): #LINKED LIST head:term,doc_freq // node: doc_num, freq in doc_num\n",
    "    list_set=[]\n",
    "\n",
    "    tmp_t=index[0][0]\n",
    "    tmp_d=index[0][1]\n",
    "    cnt=1\n",
    "    for i in range(1,len(index)):\n",
    "        tmp_term=index[i][0]\n",
    "        tmp_doc=index[i][1]\n",
    "\n",
    "        if(tmp_term==tmp_t and tmp_doc==tmp_d):\n",
    "           cnt+=1\n",
    "        else:\n",
    "            list_set.append([tmp_t,tmp_d,cnt])\n",
    "            cnt=1\n",
    "        tmp_t=tmp_term\n",
    "        tmp_d=tmp_doc\n",
    "    list_set.append([tmp_t, tmp_d, cnt])\n",
    "\n",
    "    list_all=[]\n",
    "    term=list_set[0][0]\n",
    "    list_t=List(term)\n",
    "    list_t.add(list_set[0][1],list_set[0][2])\n",
    "    for i in range(1,len(list_set)):\n",
    "        if(term!=list_set[i][0]):\n",
    "            list_all.append(list_t)\n",
    "            list_t=List(list_set[i][0])\n",
    "        list_t.add(list_set[i][1],list_set[i][2])\n",
    "        term=list_set[i][0]\n",
    "    list_all.append(list_t)\n",
    "\n",
    "    return list_all\n",
    "\n",
    "def indexing():  #vsm\n",
    "    vsm_word1 = []\n",
    "    index_doc=[]\n",
    "    indexed_list1=[]\n",
    "    for i in range(len(doc)):\n",
    "        for j in range(len(doc[i][1])):\n",
    "            index_doc.append([doc[i][1][j],i])\n",
    "\n",
    "    index_doc.sort(key=itemgetter(0))\n",
    "\n",
    "    indexed_list1=listing(index_doc)\n",
    "\n",
    "    for i in range(len(indexed_list1)):  # 각 단어별 weight 계산 단어 1개\n",
    "        vsm_word1.append([0 for j in range(len(doc) + 1)])\n",
    "        vsm_word1[i][0] = indexed_list1[i].term\n",
    "        p = indexed_list1[i].head\n",
    "        while (p != None):\n",
    "            w = (1 + math.log2(p.dtf)) * math.log2(len(doc) / indexed_list1[i].freq)\n",
    "            #w=p.dtf\n",
    "            vsm_word1[i][p.doc + 1] = float(w)\n",
    "            p = p.next\n",
    "    return vsm_word1\n",
    "\n",
    "vsm=indexing()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vsm_=np.zeros((len(vsm),len(vsm[0])-1))\n",
    "for i in range(len(vsm_)): #vsm\n",
    "        for j in range(len(vsm_[i])):\n",
    "            vsm_[i][j]=vsm[i][j+1]\n",
    "vsm_t=vsm_.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim_a=[]\n",
    "\n",
    "for i in range(len(singer)):\n",
    "    list_sim=[]\n",
    "    for j in range(len(singer)):\n",
    "        list_sim.append(cos_sim(vsm_t[i],vsm_t[j]))\n",
    "  \n",
    "    cos_sim_a.append(list_sim)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Max accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eminem      dr-dre :   0.161\n",
      "ghostface-killah      50-cent :   0.163\n",
      "50-cent      ghostface-killah :   0.163\n",
      "dr-dre      2pac :   0.184\n",
      "drake      chris-brown :   0.118\n",
      "2pac      dr-dre :   0.184\n",
      "beyonce-knowles      chris-brown :   0.119\n",
      "ariana-grande      eminem :   0.068\n",
      "chris-brown      eminem :   0.136\n",
      "glen-campbell      eddy-arnold :   0.109\n",
      "ciara      chris-brown :   0.122\n",
      "ed-sheeran      eminem :   0.1\n",
      "garth-brooks      glen-campbell :   0.081\n",
      "billy-ray-cyrus      bryan-adams :   0.078\n",
      "brad-paisley      eminem :   0.082\n",
      "bryan-adams      the-calling :   0.084\n",
      "eddy-arnold      glen-campbell :   0.109\n",
      "beatles      eminem :   0.072\n",
      "coldplay      the-calling :   0.053\n",
      "the-calling      bryan-adams :   0.084\n",
      "the-doors      ghostface-killah :   0.068\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(cos_sim_a)):\n",
    "    test = cos_sim_a[i][:]\n",
    "    test.pop(test.index(max(test)))\n",
    "    a = cos_sim_a[i].index(max(test))\n",
    "    print(\"\" + singer[i] +\"      \"  + singer[a]+ \" :   \" + str(max(test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Min accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eminem/coldplay :   0.05\n",
      "ghostface-killah/the-calling :   0.045\n",
      "50-cent/coldplay :   0.038\n",
      "dr-dre/the-calling :   0.037\n",
      "drake/coldplay :   0.032\n",
      "2pac/coldplay :   0.042\n",
      "beyonce-knowles/eddy-arnold :   0.033\n",
      "ariana-grande/coldplay :   0.029\n",
      "chris-brown/glen-campbell :   0.038\n",
      "glen-campbell/ciara :   0.028\n",
      "ciara/the-calling :   0.024\n",
      "ed-sheeran/ciara :   0.042\n",
      "garth-brooks/ciara :   0.037\n",
      "billy-ray-cyrus/ciara :   0.032\n",
      "brad-paisley/ariana-grande :   0.035\n",
      "bryan-adams/ciara :   0.043\n",
      "eddy-arnold/ciara :   0.026\n",
      "beatles/coldplay :   0.035\n",
      "coldplay/ciara :   0.025\n",
      "the-calling/ciara :   0.024\n",
      "the-doors/ciara :   0.031\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(cos_sim_a)):\n",
    "    a = cos_sim_a[i].index(min(cos_sim_a[i]))\n",
    "    print(\"\" + singer[i] +\"/\"  + singer[a]+ \" :   \" + str(min(cos_sim_a[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
