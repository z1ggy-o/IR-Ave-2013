{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the Most Representive songs of the singer\n",
    "\n",
    "## Idea\n",
    "\n",
    "1. Have lyrics of each singer, use that to build a VSM\n",
    "2. Sort lyric vectors, find the most important terms of each song (like top 30 terms)\n",
    "3. Get all the important terms of each song together, sort them by df, then choose the top [100] terms as the represent terms of this singer.\n",
    "4. For each lyric vector, sum the representive terms' weight together, treat it as this song's score\n",
    "5. Find the top 20 songs through the scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build VSM For Each Singer\n",
    "\n",
    "1. Matching singers and their songs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/zgy/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import regexp_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../mylyrics00.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _singer_song_dic(data):\n",
    "    '''Build singer-song dictionay\n",
    "    \n",
    "    Dictionary format:\n",
    "    {singer_name: {song_name: lyrics}}\n",
    "    '''\n",
    "    \n",
    "    singer_songs = {}\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        singer = data.iloc[i]['artist']\n",
    "        song = data.iloc[i]['song']\n",
    "        lyric = data.iloc[i]['lyrics']\n",
    "        \n",
    "        \n",
    "        if singer not in singer_songs:\n",
    "            temp = {song: lyric}\n",
    "            singer_songs[singer] = temp\n",
    "        else:\n",
    "            singer_songs[singer][song] = lyric\n",
    "            \n",
    "    return singer_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING\n",
    "\n",
    "singer_songs = _singer_song_dic(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is tested\n",
    "def _update_inverted_index(name, lyrics, inverted_index):\n",
    "    '''Create inverted index, count doc vector length\n",
    "\n",
    "    Read contents form file, remove punctuation and stopwords to get terms.\n",
    "    Count tf of this doc, then update inverted index.\n",
    "    \n",
    "    inverted_index\n",
    "    '''\n",
    "    \n",
    "    indices = {}\n",
    "    punctuation = re.compile(r'[^\\w\\s\\']')\n",
    "    \n",
    "    ###\n",
    "    # Count term frequency\n",
    "    ###\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    lyrics_split = re.sub(punctuation, ' ', lyrics.lower()).split()\n",
    "    \n",
    "    for term in lyrics_split:\n",
    "        if term in stop_words:\n",
    "            continue\n",
    "        elif term in indices:\n",
    "            indices[term] += 1\n",
    "        else:\n",
    "            indices[term] = 1\n",
    "    \n",
    "    ###\n",
    "    # Update inverted_index\n",
    "    ###\n",
    "    for term, frequency in indices.items():\n",
    "        if term in inverted_index:\n",
    "            posting = inverted_index[term]\n",
    "            posting.append((name, frequency))\n",
    "            inverted_index[term] = posting\n",
    "        else:\n",
    "            inverted_index[term] = [(name, frequency)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_weight(tf, df, n_songs):\n",
    "    \n",
    "    idf = math.log(n_songs / df)\n",
    "\n",
    "    tf_normalized = 1 + math.log(tf)\n",
    "\n",
    "    weight = tf_normalized * idf\n",
    "    return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _build_song_vector(inverted_index, n_songs):\n",
    "    '''Build term-weight vector for songs\n",
    "    \n",
    "    Compute the tf-idf weight, {term: weight}\n",
    "    \n",
    "    return:\n",
    "        dic: a dictionary which format is {song: {term: weight}}\n",
    "    '''\n",
    "    \n",
    "    song_vectors = {}\n",
    "    \n",
    "    for term, posting in inverted_index.items():\n",
    "        df = len(posting)\n",
    "        for pair in posting:\n",
    "            song, tf = pair\n",
    "            weight = _compute_weight(tf, df, n_songs)\n",
    "            if song not in song_vectors:  # Create song vec\n",
    "                song_vectors[song] = {term: weight}\n",
    "            else:\n",
    "                song_vectors[song][term] = weight  # Add new term into vec\n",
    "                \n",
    "    return song_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_top_songs(inverted_index, terms):\n",
    "    '''Count rep terms' frequency, use that to pick rep songs\n",
    "    \n",
    "    Args:\n",
    "        inverted_index: inverted index of this singer's songs\n",
    "            format => {term: [(song, tf),]}\n",
    "        terms: this singer's representive terms\n",
    "    Return:\n",
    "        top_songs(list): a list that contains the name of songs, order by score\n",
    "    '''\n",
    "    \n",
    "    song_scores = {}\n",
    "    for term in terms:\n",
    "        posting = inverted_index[term]\n",
    "        for song, _ in posting:\n",
    "            if song in song_scores:\n",
    "                song_scores[song] += 1\n",
    "            else:\n",
    "                song_scores[song] = 1\n",
    "                \n",
    "    top_songs = sorted(song_scores.items(), key=lambda kv: kv[1], reverse=True)\n",
    "    return top_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _find_rep_songs(songs, num_of_songs, num_of_terms):\n",
    "    '''Find the most representive songs of this singer\n",
    "    \n",
    "    Choose songs by compare the scores which is sum the weight of each important term in that song.\n",
    "    \n",
    "    Args:\n",
    "        songs(dic): a dictionary {song: lyrics}\n",
    "        num_of_songs: number of representive songs you want to choose\n",
    "        num_of_terms: number of important words we want to score the songs\n",
    "        \n",
    "    Return:\n",
    "        rep_songs(dic): a dictionary {song: lyrics}, size will less or equal to num_of_songs\n",
    "    '''\n",
    "    \n",
    "    inverted_index = {}\n",
    "    \n",
    "    n_songs = len(songs)\n",
    "    if n_songs <= num_of_songs:  # Do not need to choose if not has enough songs\n",
    "        return songs\n",
    "    \n",
    "    # Build inverted index\n",
    "    for name, lyrics in songs.items():\n",
    "        _update_inverted_index(name, lyrics, inverted_index)\n",
    "        \n",
    "    # build song vector\n",
    "    song_vectors = _build_song_vector(inverted_index, n_songs)\n",
    "    \n",
    "    # sort by weight, get top words (put them into a set)\n",
    "    selected_terms = set()\n",
    "    \n",
    "    for song, vector in song_vectors.items():\n",
    "        sorted_v = sorted(vector.items(), key=lambda kv: kv[1], reverse=True)\n",
    "        select_range = sorted_v[:num_of_terms + 1]\n",
    "        for term, _ in select_range:\n",
    "            selected_terms.add(term)\n",
    "    \n",
    "    # get score of each song\n",
    "    song_sorted = _get_top_songs(inverted_index, selected_terms)\n",
    "    print(song_sorted)\n",
    "    # get rep songs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('bet-shady-2-0-cypher', 194), ('shady-2-0-cypher', 193), ('westwood-freestyle-2010', 181), ('campaign-speech', 173), ('doa-rai-me', 150), ('hailie-s-revenge', 150), ('quitter', 147), ('just-rhymin-wit-proof', 146), ('doe-rae-me', 145), ('detroit-vs-everybody', 142), ('detroit-vs-everybody-remix', 142), ('evil-twin', 141), ('2-0-boys', 139), ('doe-ray-me', 135), ('shady-records-mob-squad', 134), ('zane-lowe-bbc-radio-interview-part-2', 134), ('zane-lowe-bbc-radio-interview-part-1', 134), ('vegas', 134), ('calm-down', 130), ('rap-god', 125), ('rap-god-french-version', 125), ('shady-xv-cypher', 124), ('shadyxv', 124), ('hail-mary-2003-ja-rule-diss', 123), ('wicked-ways', 121), ('love-game', 120), ('loud-noises', 118), ('rhyme-or-reason', 116), ('groundhog-day', 115), ('dont-approach-me', 115), ('bad-guy', 115), ('under-the-influence', 115), ('cry-now-shady-remix', 114), ('cry-now-remix', 114), ('we-re-back', 114), ('syllabes', 113), ('psychopath-killer', 113), ('fast-lane-remix', 111), ('we-all-die-1-day', 111), ('we-all-die-someday', 111), ('we-all-die-one-day', 111), ('the-anthem', 110), ('get-you-mad', 109), ('fast-lane', 109), ('rap-game', 109), ('rap-game-bump-heads', 109), ('crimirnal', 109), ('syllables', 108), ('on-you', 108), ('marshell-mathers', 108), ('get-ready', 107), ('bump-heads', 107), ('tim-westwood-freestyle', 107), ('a-e', 107), ('no-one-s-iller-than-me', 106), ('no-one-s-iller-then-me', 106), ('no-one-s-iller', 106), ('marshall-mathers', 106), ('8-mile-road', 106), ('8-mile', 105), ('our-house', 105), ('don-t-front', 105), ('kids', 104), ('the-kids', 104), ('back-to-the-music', 104), ('when-the-music-stops', 104), ('square-dance', 104), ('brainless', 104), ('off-the-wall', 104), ('i-m-on-everything', 103), ('stan', 103), ('stan-clean-version', 103), ('stan-explicit', 103), ('busa-rhyme', 103), ('cold-wind-blows', 103), ('marshall-mathers-lp', 103), ('roman-s-revenge', 103), ('celebrity', 102), ('we-on-fire-ja-diss', 102), ('can-i-bitch', 102), ('my-band', 101), ('session-one', 101), ('my-darling', 101), ('keep-talking', 100), ('all-she-wrote', 100), ('shit-on-you', 100), ('poo-butt-day', 99), ('bad-meets-evil', 99), ('sway-in-the-morning-freestyle', 99), ('bitch-please-part-ii', 97), ('bitch-please-part-2', 97), ('bitch-please-ii', 97), ('bitch-please-iii', 97), ('the-reunion', 97), ('throw-it-up', 97), ('so-far', 97), ('white-trash-party-remix', 97), ('right-for-me', 97), ('girls', 96), ('when-to-stand-up', 96), ('headlights', 96), ('won-t-back-down', 96), ('wonaeur-tm-t-back-down', 96), ('can-t-back-down', 96), ('kings-never-die', 96), ('as-the-world-turns', 95), ('welcome-to-hell', 94), ('w-t-p', 94), ('patiently-waiting', 94), ('curtains-down', 93), ('criminal', 93), ('forever', 93), ('where-i-m-at', 92), ('fly-away', 92), ('armageddon-freestyle', 92), ('all-fall-down', 92), ('mockingbird', 91), ('drama-setter', 91), ('going-through-changes', 91), ('cocaine', 90), ('untitled-freestyle', 90), ('moking-bird', 90), ('i-tried-so-hard-remix', 90), ('drugs-got-a-hold-of-me', 90), ('living-proof', 89), ('my-1st-single', 89), ('if-i-get-locked-up-tonight-with-dr-dre', 89), ('if-i-get-locked-up-tonite', 89), ('eminem-part-1', 89), ('deja-vu', 89), ('above-the-law', 89), ('writer-s-block', 89), ('one-last-time', 88), ('one-last-time-encore-f-dr-dre-50-cent', 88), ('crack-a-bottle', 88), ('business', 88), ('baby', 88), ('the-last-hit', 87), ('9-1-1', 87), ('threesixfive', 87), ('scary-movies', 87), ('hell-breaks-loose', 87), ('hell-breaks-lose', 87), ('cinderella-man', 87), ('nail-in-the-coffin', 87), ('stir-crazy', 86), ('3-verses', 86), ('don-t-push-me', 86), ('stay-wide-awake', 86), ('encore-curtains-down', 86), ('encore', 86), ('yellow-brick-road', 86), ('mosh', 86), ('psycho', 86), ('purple-hills', 86), ('kill-you', 86), ('rush-ya-clique-with-outsidaz', 86), ('nuttin-to-do', 86), ('come-on-in', 86), ('turn-me-loose-with-limp-bizkit', 85), ('berzerk', 85), ('everyone-has-been-shot', 85), ('dead-wrong-remix', 85), ('dead-wrong', 85), ('lighters', 85), ('one-shot-2-shot', 85), ('1-shot-2-shot', 85), ('one-shot', 85), ('one-shot-8-mile-sundtrack', 85), ('y-all-ready-know', 85), ('radio', 85), ('the-show-down', 84), ('dudey', 84), ('im-back', 84), ('thats-all-she-wrote', 84), ('she-a-lie', 83), ('shake-that-ass-for-me-remix', 83), ('guts-over-fear', 83), ('welcome-2-detroit-city', 82), ('welcome-2-detroit', 82), ('welcome-2-hell', 82), ('the-warning', 82), ('i-think-my-dads-gone-crazy', 82), ('mommy', 82), ('fight-music', 82), ('bully', 82), ('luv-me', 82), ('curtains-up-evil-deeds', 82), ('airplanes-part-2', 81), ('part-ii', 81), ('what-s-the-difference', 81), ('white-america', 81), ('superman', 81), ('i-m-shady', 81), ('kim', 81), ('evil-deeds', 81), ('bad-guys-always-die', 80), ('say-what-you-say', 80), ('difficult', 80), ('when-we-re-gone', 80), ('when-i-m-gone', 80), ('when-i-m-gone-explicit', 80), ('best-rapper-alive', 80), ('we-don-t-give-a-fuck', 80), ('no-love', 80), ('just-don-t-give-a-fuck', 80), ('i-just-don-t-give-a-fuck', 80), ('eminem-no-love-explixit-version', 80), ('we-shine', 80), ('murder-murder-remix', 79), ('murder-murder', 79), ('fuck-off', 79), ('nail-in-your-coffin-part-1', 79), ('its-murda-cable-guy-remix', 79), ('survival', 79), ('here-we-go', 79), ('hit-me-with-your-best-shot', 79), ('the-real-slim-shady', 79), ('seduction', 78), ('purple-pills', 78), ('goat', 78), ('spend-some-time', 78), ('rain-man', 78), ('the-sauce', 78), ('renegade', 78), ('guilty-conscience', 78), ('guilty-conscience-director-s-cut', 78), ('legacy', 78), ('pistol-poppin', 78), ('city-of-gold', 78), ('rap-poets', 78), ('on-fire', 78), ('i-run-rap', 78), ('another-sentencing', 77), ('schooling', 77), ('fuck-you-lab-rat-remix', 77), ('so-much-better', 77), ('97-bonnie-and-clyde', 77), ('drug-ballad', 77), ('fine-line', 77), ('old-time-s-sake', 76), ('for-old-times-sake', 76), ('brain-damage', 76), ('low-down-dirty', 76), ('down', 76), ('drips', 76), ('by-my-side', 76), ('the-gay-i-am-way-i-am-skit', 76), ('hellbound', 76), ('elevator', 76), ('ass-like-that', 76), ('like-that-edited-version', 76), ('ain-t-nuttin-but-music', 76), ('go-to-sleep-bitch-die', 75), ('just-lose-it-instrumental', 75), ('just-lose-it', 75), ('just-lose-it-video', 75), ('just-lose-it-explicit', 75), ('christopher-reeve', 75), ('change-it-all-back', 75), ('forgot-about-dre', 75), ('oh-no', 75), ('take-from-me', 75), ('love-me', 75), ('asshole', 75), ('shots-fired', 74), ('comin-out-my-closet-parody', 74), ('drop-world', 74), ('sing-for-the-moment', 74), ('hard', 74), ('echo', 74), ('still-don-t-give-a-fuck', 74), ('talkinaeur-tm-2-myself', 73), ('talkin-2-myself', 73), ('talkin', 73), ('with-smiley-parody-of-without-me', 73), ('goin-crazy', 73), ('outlet', 73), ('richard', 73), ('same-song-dance', 73), ('youaeur-tm-re-never-over', 72), ('you-re-never-over', 72), ('go-to-sleep', 72), ('313', 72), ('almost-famous', 72), ('monkey-see-monkey-do', 72), ('underground', 72), ('you-don-t-know', 72), ('rabbit-run', 72), ('run-rabbit-run', 72), ('no-return', 72), ('cum-on-everybody', 72), ('buffalo-bill', 72), ('rhymin-wordz-freestyle', 72), ('ricky-ticky-toc', 71), ('i-need-a-doctor', 71), ('my-dad-s-gone-crazy', 71), ('hello', 71), ('3-a-m', 71), ('remember-me', 71), ('bagpipes-from-baghdad', 71), ('without-me', 71), ('without-me-un-edited', 71), ('maxine', 70), ('drop-the-bomb-on-em', 70), ('im-spacebound', 70), ('ridaz', 70), ('infinite', 70), ('cleanin-out-my-closet-explicit', 70), ('beautiful', 70), ('beautiful-new', 70), ('tour-aftermath', 70), ('who-knew', 70), ('freestyle-radio-1', 69), ('talkin-all-that', 69), ('it-s-been-real', 69), ('how-come', 69), ('cleanin-out-my-closet', 69), ('hailie-s-song', 69), ('cleaning-out-my-closet', 69), ('lose-ya-self', 69), ('hello-good-morning-remix', 69), ('american-psycho', 69), ('warrior-part-2', 69), ('role-model', 68), ('phenomenal', 68), ('i-can-be', 68), ('way-i-am-the', 68), ('the-way-i-am', 68), ('the-way-i-am-explicit', 68), ('like-toy-soldiers', 68), ('like-toy-soilders', 68), ('like-toy-soldiers-explicit', 68), ('rock-bottom', 68), ('music-box', 68), ('wanna-be-me', 68), ('if-i-had', 67), ('if-i-had-radio-edit', 67), ('desperation', 67), ('so-bad', 67), ('tonight', 67), ('rabbit-vs-lickilty-split-8-mile-freestlye', 67), ('split-shine', 67), ('not-affraid', 67), ('the-apple', 67), ('just-the-two-of-us-radio-edit', 67), ('just-the-two-of-us', 67), ('we-ain-t', 67), ('must-be-the-ganja', 66), ('it-must-be-the-ganja', 66), ('love-the-way-you-lie', 66), ('i-m-sorry-mama-full-song', 66), ('hailie-and-me', 66), ('clean-out-my-closet', 66), ('my-words-are-weapons', 66), ('words-are-weapons', 66), ('adrenline-rush', 66), ('jimmy-crack-corn-remix', 66), ('jimmy-crack-corn', 66), ('we-made-you', 66), ('till-i-collapse-remix', 65), ('till-i-collapse', 65), ('we-the-realest-label', 65), ('my-name-is-bootleg-version', 65), ('my-name-is-radio-video-edit', 65), ('hi-my-name-is', 65), ('my-name-is', 65), ('my-name-is-real-dirty', 65), ('my-name-is-explicit', 65), ('microphone-fiend', 65), ('stimulate', 65), ('its-your-time', 65), ('space-bound', 65), ('jealousy-woes', 65), ('jealousy-woes-ii', 65), ('fuckin-crazy', 65), ('never-2-far', 65), ('slim-shade-ep', 65), ('classic-shit', 64), ('medicine-ball', 64), ('halie-s-song', 64), ('a-drop-in-the-ocean', 64), ('taking-my-ball', 64), ('my-balls', 64), ('my-fault', 64), ('black-juice', 64), ('50-ways', 63), ('my-mom', 63), ('everything-is-shady', 63), ('lose-yourself', 63), ('not-afraid', 62), ('throw-that', 62), ('soldier-the-goat-remix-1st-verse', 62), ('soldier', 62), ('it-s-ok', 62), ('say-goodbye-hollywood', 62), ('die-alone', 62), ('emulate', 62), ('lose-yourself-original-demo-version', 62), ('ballin-uncontrollably', 61), ('wee-wee', 61), ('i-love-you-more-kim2', 61), ('the-monster', 60), ('no-apologies', 60), ('invasion', 60), ('murder', 60), ('twisted', 60), ('i-m-having-a-relapse', 60), ('bad-influence', 60), ('get-low', 60), ('the-re-up', 60), ('back-stabber', 60), ('fly-away-remix', 59), ('despicable', 59), ('big-weenie', 59), ('beautiful-pain', 59), ('i-got-this-feelin', 59), ('freestyle-dissin-the-source', 58), ('shake-that-fet-nate-dog', 58), ('shake-that', 58), ('shake-that-remix', 58), ('i-love-you-more', 58), ('symphony-in-h', 58), ('i-remember', 57), ('8-mile-runnin', 57), ('stronger-than-i-was', 57), ('crackers-n-cheese', 57), ('we-as-americans', 57), ('over-freestyle', 57), ('love-you-more', 57), ('wake-up-show-freestyle', 57), ('8-mile-freestyle-vs-lickty-spilt', 56), ('pistol-pistol-remix-obie-trice', 56), ('tylenol-island', 56), ('open-mic', 56), ('what-if-i-was-white', 55), ('what-if-he-was-white', 55), ('family-problems', 55), ('facebook-q-a', 55), ('jingle-bells', 55), ('crazy-in-love', 54), ('muurder', 54), ('the-night-before-christmas', 54), ('till-hell-freezes-over', 54), ('failed-destiny', 54), ('searchin', 53), ('b-rabbit-vs-lyckety-splyt', 53), ('need-a-doctor', 53), ('b-rabbit-vs-papa-doc-freestyle-from-8-mile', 53), ('never-enough', 53), ('the-world-ain-t-ready-for-me-yet', 53), ('8-mile-freestyle-pt-ii-vs', 53), ('biterphobia', 52), ('topless', 52), ('watch-dees', 52), ('atlanta-on-fire', 52), ('forgive-me', 52), ('8-mile-freestyle-pt-iii-vs', 52), ('careful-what-you-wish-for', 51), ('ski-mask-way-eminem-remix', 51), ('wanksta', 51), ('insane', 51), ('8-mile-freestyle', 51), ('fack', 51), ('fack-explicit', 51), ('venger-s-a-big-fat-bitch', 51), ('public-enemy-1', 51), ('dare-to-dream', 50), ('25-to-life', 50), ('25-to-life-remix', 50), ('life', 50), ('places-to-go', 49), ('relapse', 49), ('b-rabbit-v-papa-doc', 49), ('dear-marshall', 49), ('get-money-freestyle', 49), ('street-lights', 49), ('love-the-way-you-lie-part-ii', 49), ('b-rabbit-v-s-lotto-2nd-battle-from-8-mile', 49), ('get-money', 48), ('chonkyfire-freestyle', 48), ('rabbit-vs-papa-doc-freestyle-from-8-mile', 47), ('it-was-just-a-dream', 47), ('eminem-exclusive-freestyle', 47), ('any-man', 47), ('fubba-u-cubba-cubba', 46), ('amityville', 45), ('14-amityville', 43), ('devil-s-night-intro', 43), ('the-hills-remix', 42), ('whose-arm-is-this-freestyle', 41), ('classy-nigg-a', 41), ('eminem-freestyle', 41), ('smack-that', 41), ('smack-that-remix', 41), ('give-me-the-ball', 41), ('b-rabit-1st-battle', 40), ('classy-nigg', 40), ('d12-project', 39), ('trapped', 39), ('bea', 38), ('chemical-warfare', 37), ('the-cypher', 37), ('sweet-home-alabama', 37), ('puke', 36), ('insult-to-injury', 35), ('make-some-noise', 35), ('rabbit-vs-lotto-8-mile-freestyle', 35), ('we-re-still-1-freestyle', 34), ('steve-berman', 34), ('steve-berman-skit', 34), ('dr-west', 34), ('gaddafi-the-coward', 33), ('the-people-s-champ', 32), ('zucker-im-kaffee', 32), ('letter-to-myself', 31), ('mtv-awards', 31), ('lunch-truck-freestyle', 31), ('number-one', 30), ('8-mile-chapter-7-parking-lot-battle-b-rabbit', 30), ('artificial-flavor', 30), ('a-kiss', 30), ('nobody-s-perfect', 29), ('pills', 29), ('w-t-p-remix', 29), ('thug-luv', 29), ('b-g-s-in-tha-fast-lane', 29), ('the-bong-song', 28), ('the-presentation', 28), ('bane', 28), ('letter-to-detroit', 27), ('things-get-worse', 27), ('em-calls-paul-skit', 26), ('the-kiss-skit', 26), ('this-is-fucking-bullshit', 26), ('i-live-at-home-in-a-trailor', 26), ('armload-of-awards', 25), ('public-service-announcement', 25), ('carrington-pool', 24), ('w-e-g-o-interlude', 24), ('shady-narcotics-intro', 23), ('shady-narcotics', 23), ('tv-total-freestyle-2009', 21), ('all-about-it', 21), ('mrmathers', 20), ('nut-up', 20), ('billion-bucks', 19), ('eye-of-the-tiger', 18), ('rapcity-freestyle', 18), ('tonya', 18), ('going-solo', 18), ('public-service-announcement-2000', 17), ('the-art-of-rap-freestyle', 17), ('early-years', 16), ('ken-kaniff', 16), ('bitch', 16), ('soap-skit', 15), ('soap', 15), ('paul', 15), ('paul-skit', 15), ('intro-curtain-call-the-hits', 14), ('intro', 14), ('intro-slim-shady', 14), ('intro-explicit', 14), ('parking-lot', 14), ('wasting-my-time', 14), ('paul-rosenberg-skit', 12), ('curtains-close', 12), ('curtains-close-skit', 12), ('lounge', 11), ('curtains-up-encore-version', 9), ('curtains-up', 9), ('final-thought-skit', 7), ('hot-metal', 6), ('earthquake-remix', 6), ('senate-hearings', 5), ('the-eminem-show', 2), ('eminem-s-future', 1)]\n"
     ]
    }
   ],
   "source": [
    "# TESTING\n",
    "\n",
    "_find_rep_songs(singer_songs['eminem'], 20, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rep_songs(num_of_songs, file_path):\n",
    "    '''Get each singer's representive songs\n",
    "    \n",
    "    Args: \n",
    "        num_of_songs: number of songs you want to get from each singer\n",
    "        file_path: path of input data file\n",
    "    Return:\n",
    "        dic: A dictionary which format is {singer, {song: lyrics}}\n",
    "    '''\n",
    "    \n",
    "    # Read data from file\n",
    "    # singer_songs = singer_song_dic(data)\n",
    "    \n",
    "    representive_songs = {}  # return dic\n",
    "    for singer, songs in singer_songs.items():\n",
    "        rep = find_rep_songs(songs)\n",
    "        representive_songs[singer] = rep\n",
    "        \n",
    "    return representive_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def search():\n",
    "    '''Search query matched documents\n",
    "\n",
    "    Compute the similarity between query and documents.\n",
    "    Print out related documents in decrease score order\n",
    "    '''\n",
    "\n",
    "    query = input('Please entry your query (use Ctrl-C to exit): ')\n",
    "    # query preprocessing\n",
    "    scores = {}\n",
    "    for term in re.sub(punctuation, ' ', query).split():\n",
    "        if term not in inverted_index:\n",
    "            continue\n",
    "        weight = compute_weight(1, len(inverted_index[term]))\n",
    "        compute_score(term, weight, scores)\n",
    "\n",
    "    for id in scores.keys():\n",
    "        weight_production = scores[id]\n",
    "        scores[id] = weight_production / length_of_docs[id]\n",
    "\n",
    "    sorted_docs = sorted(scores.items(), key=lambda kv: kv[1], reverse=True)\n",
    "    if (not sorted_docs):\n",
    "        print(f'\\nThere is no relevant document.')\n",
    "    else:\n",
    "        print('\\nSearch results are: ')\n",
    "        for doc in sorted_docs:\n",
    "            print('-> ' + docs_list[doc[0]])\n",
    "    print()\n",
    "\n",
    "    print('Scores are:')\n",
    "    for score in sorted_docs:\n",
    "        print(score)\n",
    "    print()\n",
    "\n",
    "\n",
    "#\n",
    "# Helper functions\n",
    "#\n",
    "def update_inverted_index(doc, doc_id):\n",
    "    '''Create inverted index, count doc vector length\n",
    "\n",
    "    Read contents form file, remove punctuation and stopwords to get terms.\n",
    "    Count tf of this doc, then update inverted index.\n",
    "    '''\n",
    "    ###\n",
    "    # Count term frequency\n",
    "    ###\n",
    "    doc_path = 'text/' + doc.strip()\n",
    "    indices = {}\n",
    "    with open(doc_path, 'r') as f:\n",
    "        raw_line = f.readline()\n",
    "        while(raw_line):\n",
    "            line = raw_line.strip()\n",
    "            if (not line):\n",
    "                raw_line = f.readline()\n",
    "                continue\n",
    "            for word in re.sub(punctuation, ' ', line).split():\n",
    "                word_low = word.lower()\n",
    "                if word_low in stopwords:\n",
    "                    continue\n",
    "                elif word_low in indices:\n",
    "                    indices[word_low] += 1\n",
    "                else:\n",
    "                    indices[word_low] = 1\n",
    "            raw_line = f.readline()\n",
    "\n",
    "    ###\n",
    "    # Update inverted_index\n",
    "    ###\n",
    "    for pair in indices.items():\n",
    "        term, frequency = pair\n",
    "        if term in inverted_index:\n",
    "            posting = inverted_index[term]\n",
    "            posting.append((doc_id, frequency))\n",
    "            inverted_index[term] = posting\n",
    "        else:\n",
    "            inverted_index[term] = [(doc_id, frequency)]\n",
    "\n",
    "\n",
    "def compute_doc_length():\n",
    "    num_of_docs = len(docs_list)\n",
    "    docs_weights = [[] for _ in range(num_of_docs)]\n",
    "\n",
    "    # Compute weights\n",
    "    for item in inverted_index.items():\n",
    "        _, posting = item\n",
    "        df = len(posting)\n",
    "        for pair in posting:\n",
    "            id, tf = pair\n",
    "            docs_weights[id].append(compute_weight(tf, df))\n",
    "\n",
    "    # Compute lengths\n",
    "    for v_weight in docs_weights:\n",
    "        v_sq = [x**2 for x in v_weight]\n",
    "        length = math.sqrt(sum(v_sq))\n",
    "        length_of_docs.append(length)\n",
    "\n",
    "\n",
    "def compute_score(term, weight_tq, scores):\n",
    "    posting = inverted_index[term]\n",
    "    df = len(posting)\n",
    "    for pair in posting:\n",
    "        id, tf = pair\n",
    "        weight_td = compute_weight(tf, df)\n",
    "\n",
    "        if id in scores:\n",
    "            s = scores[id]\n",
    "            scores[id] = s + weight_td * weight_tq\n",
    "        else:\n",
    "            scores[id] = weight_td * weight_tq\n",
    "\n",
    "\n",
    "def compute_weight(tf, df):\n",
    "    num_of_docs = len(docs_list)\n",
    "    idf = math.log(num_of_docs/df)\n",
    "\n",
    "    tf_normalized = 1 + math.log(tf)\n",
    "\n",
    "    weight = tf_normalized * idf\n",
    "    return weight\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    indexing()\n",
    "    while(True):\n",
    "        search()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
